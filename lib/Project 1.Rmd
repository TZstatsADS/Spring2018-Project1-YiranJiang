---
title: "Project 1- The sentiment in the inauguration speech and the GDP growth rate"
author: "yj2462"
date: "2018/1/27"
output: html_notebook
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

# Step 0: check and install needed packages. Load the libraries and functions. 

```{r, message=FALSE, warning=FALSE}
packages.used=c("qdap", "lattice", "grid", 
                "sentimentr", "nnet", "dplyr",
                "png", "ggplot2","MASS", "devtools",
                "reshape","syuzhet","rJava","rvest")

# check packages that need to be installed.
packages.needed=setdiff(packages.used, 
                        intersect(installed.packages()[,1], 
                                  packages.used))
# install additional packages
if(length(packages.needed)>0){
  install.packages(packages.needed, dependencies = TRUE)
}

library("syuzhet")
library("rvest")
library("rJava")
library("qdap")
library("sentimentr")
library("lattice")
library("grid")
library("nnet")
library("MASS")
library("devtools")
library("png")
library("dplyr")
library("ggplot2")
library("reshape")

source("../lib/plotstacked.R")
source("../lib/speechFuncs.R")
```

# Step 1: Data harvest: scrap speech URLs and load in the full text.

Preparing for the Sentiment analysis.

```{r}

source_url('https://gist.githubusercontent.com/fawda123/7471137/raw/466c1474d0a505ff044412703516c34f1a4684a5/nnet_plot_update.r')

main.page <- read_html(x = "http://www.presidency.ucsb.edu/inaugurals.php")

inaug=f.speechlinks(main.page)
inaug=inaug[-nrow(inaug),]
inaug.list=read.csv("../data/inauglist.csv", stringsAsFactors = FALSE)

inaug.list=cbind(inaug.list, inaug)

inaug.list$fulltext=NA
for(i in seq(nrow(inaug.list))) {
  text <- read_html(inaug.list$urls[i]) %>% # load the page
    html_nodes(".displaytext") %>% # isloate the text
    html_text() # get the text
  inaug.list$fulltext[i]=text

}

```

# Step 2: Data cleaning: read the GDP data and clean the data.

We are going to load the GDP data over years while we only need those when president inauguration speech occurs.

```{r}

date <- inaug.list$links 
date <- substring(date,nchar(date)-3,nchar(date)) # We only need the information of Years in the date.

GDP <- read.csv("../data/GDP.csv")
GDP <- rbind(c("1900",as.numeric(20.7)),GDP)
colnames(GDP) <- c("Year","Growth")
GDP$Growth <- as.numeric(GDP$Growth)

# The data contains only the Total GDP, thus we should calculate the GDP growth rate.
rate <- NULL
for (i in 1:nrow(GDP)){
  if (i == 1){
    rate <- c(NaN)
  }
  this.rate <- (GDP$Growth[i] - GDP$Growth[i-1])/GDP$Growth[i]
  rate <- c(rate,this.rate)
}


GDP$Growth_rate <- rate
GDP <- GDP %>%
  filter(GDP$Growth_rate, Year %in% date) # We only need the years when the inauguration speech occurs.


NewGDP <- data.frame(rbind(c("2013",0,0.017),c("2017",0,0.026))) # Add some recent data manually.
colnames(NewGDP) <- c("Year","Growth","Growth_rate")
GDP <- rbind(GDP,NewGDP)

head(GDP)

```

# Step 3: Sentiment analysis: analyze the sentiment in each inauguration speech.

```{r}

emotions_per_year <- NULL
for(i in 1:nrow(inaug.list)){
  sentences=sent_detect(inaug.list$fulltext[i],
                        endmarks = c("?", ".", "!", "|",";"))
  if(length(sentences)>0){
    emotions=get_nrc_sentiment(sentences)
    word.count=word_count(sentences)
    emotions=diag(1/(word.count+0.01))%*%as.matrix(emotions)
    emotions <- as.data.frame(emotions)
    emotions <- emotions %>%
      summarise(anger = mean(anger,na.rm =TRUE), 
                anticipation = mean(anticipation,na.rm =TRUE),
                disgust = mean(disgust,na.rm =TRUE),
                fear = mean(fear,na.rm =TRUE),
                joy = mean(joy,na.rm =TRUE),
                sadness = mean(sadness,na.rm =TRUE),
                surprise = mean(surprise,na.rm =TRUE),
                trust = mean(trust,na.rm =TRUE),
                negative = mean(negative,na.rm =TRUE),
                positive = mean(positive,na.rm =TRUE)) # summarise the sentiment data for every inauguration speech.
    emotions_per_year <- rbind(emotions_per_year,emotions) 
  }
}
emotions_per_year$Year <- date

emotions_per_year <- emotions_per_year %>%
  filter(emotions_per_year$anger, Year %in% GDP$Year)

rownames(emotions_per_year) <- emotions_per_year$Year
emotions_per_year$Year <- NULL

head(emotions_per_year)

heatmap(as.matrix(emotions_per_year,scale = "column")) # This is the visualization of our result.
```



***Note:*** This Heatmap shows a breif pattern of how the sentiment in the inauguration speech over years are clustered together.


# Step 4: Neural Network training: Train a Neural Network using BP to fit the GDP data.

Train a Neural Network using BP algorithm. We are going to fit the GDP data with the summarised sentiment data.

```{r}
set.seed(123)

norm.data <- scale(emotions_per_year[,1:10]) # Scale the data.

GDP_Growth <- as.numeric(GDP$Growth_rate)

sample <- sample(1:30,30)

GDP_New <- GDP_Growth[sample]
New.data <- norm.data[sample,] # Divide the data into test set and training set.

GDP_nn <- nnet(GDP_New[1:24]~., New.data[1:24,], size = 10 , 
           decay = 0.01, maxit = 1000, linout = T, trace = F) 

prediction <- predict(GDP_nn, norm.data)
head(prediction) # the prediction value of GDP using our mnodel.

```

We could also visualize our trained Neural Network.

```{r}
plot.nnet(GDP_nn)

```

***Note:*** The I1~I10 represents 10 inputs nodes, the H1~H10 represents 10 nodes in the hidden layer and B1~B2 are the bias nodes. O1 is the output node, which is the GDP.



# Step 5: Model assessment.

Actually, we should have used more model assessment techniques. While for this project, we only need a breif view of our prediction result.


```{r}

img <- readPNG('../figs/Trump.png')
newdate <- seq(1901,2017,by=4)
predictdata <- data.frame(prediction,GDP_Growth,newdate)
predictyear <- newdate[sample][25:30]

ggplot(data = predictdata)+
  annotation_custom(rasterGrob(img, width=unit(1,"npc"), height=unit(1,"npc")), 
                    -Inf, Inf, -Inf, Inf) +
  geom_line(mapping = aes(x = newdate, y = prediction,colour = 'red'),size=1.5)+
  geom_line(mapping = aes(x = newdate, y = GDP_Growth,colour = 'black'),size=1.5)+
  
  scale_color_discrete(name = "GDP Growth Trend", labels = c("Real Line", "Prediction Line"))+
  geom_point(data = subset(predictdata, newdate %in% predictyear),
             mapping = aes(x = newdate , y = prediction),
             col = 'blue', shape = 8 )+
  geom_text(hjust = 1, data = subset(predictdata, newdate %in% predictyear),
             mapping = aes(x = newdate , y = prediction,
                           label = newdate))+
  labs(x = 'Year', y = 'GDP Growth Rate')+
  ggtitle('The GDP Growth Over Years')


```


***Note:*** the star mark in the graph denotes the years which are predicted by our model and are not in our training set.

------------------------

# Conclusion

From the result, we could see that our model predicts quite well the GDP Growth in each year, despite some "overestimations". 

One intresting result is that our model successfully predicted the pit of GDP Growth in the year 2009, the second year after the global financial crises happened. This suggests that in the inauguration speech, the president could somewhat mentioned such trend by conducting certain sentiments in the speech.

Intuitively, the finding of our model is easy to interprete since after suffering from a reccession in economics, the president need to gain confidence from the people by conducting sentiments such as trust and anticipation.

Because of the ambiguity in the Neural Network model, some details may be missing such as what's the pattern by which those sentiments mixed to generate such results. Further study could be conducted using more complicated models.

